/** 2019 Neil Edelman, distributed under the terms of the
 [MIT License](https://opensource.org/licenses/MIT).

 This is a context-sensitive parser intended to process (parts of) a `C`
 compilation unit and extract documentation in a manner suited to those
 without knowledge of the scanner, (including the macro A_B_(Foo,Bar) is
 <A>Foo<B>Bar, if not, first see if you can compile `Doxygen`.) Generally, to
 parse a `C` document, you have to set a `C` dialect and compile it; this
 doesn't do that. Lexes documents on-line and partially parses them to give a
 very rough state with some very broad assumptions.

 Documentation commands are { "/" "*" "*"+ } and are ended with { "*"+ "/" },
 but not { "/" "*"+ "*" "/" }; one can still use this as a code break.
 Inside, \_ is emphasised block and \` is a code/math block, including
 variables; \\ is used as an escape, which escapes whatever comes after. You
 can have ASCII art inside like Kernel comments and 
 Like LaTeX, two hard returns is a paragraph. All documentation goes at most
 two lines above what it documents or it's in the header, (like this.) Multiple
 documentation on the same command is appended. Embedded in the documentation
 is <url>, <source>, \\see{<function>}, and \\seedef{<definition>}.
 
 - Paragraphs: one or more blank lines. Paragraphs at end/beginning are cut and
   new comments are always new paragraphs.
 - Headers: no; no one has time to read that.
 - Block Quotes: No.
   $"> " useful for math, but no nesting. Block quotes have a
   space. pre
 - Lists: following a blank line, " - ", but not "*", "+", or numbered lists.
   I prefer "*", but use of asterisks is problematic when dealing with Kernel
   comments, so we've skipped this.
 - Code Blocks: Yes; useful for math. Either 4 spaces or a tab. pre.
 - Horizontal Rulers: no. What are you writing a dissertation?
 - Emphasis: \_single underscores\_ at the outside of a word, only words can go
   in. *, **, \_\_, no.
 - Strikethrough: no.
 - Code Spans: \`printf\` but only code (math, etc) can go in, also use for
   naming variables; no \`\`.
 - Table of Contents: no.
 - Tables: no. This is messy.
 - Fenced Code Blocks: no.
 - Anchors: ? <fn:<fn>>? <def:<def>>?
 - HTML blocks: no.
 - '/ * !', '/ / /', '/ / !', '/ * * * * ...', no.
 - \\brief: no.
 - '/ * ! <', '/ * * <', '/ / ! <', '/ / / <': not needed; automaticlly
   concatenates.
 - [in], [out]: no; use `const` when appropriate.
 - '\\param c1', no.
 - '\@param a' or '\@param{a[, ...]}' will be concatenated.

 ![Caption text](/path/to/img.jpg)
 - ![Caption text](/path/to/img.jpg "Image title"): no.
 [The link text](http://example.net/)
 - [The link text](http://example.net/ "Link title"): no.

 Warnings when all the varibles are not mentioned at least once, in the description or the @var.

"\struct to document a C-struct.
\union to document a union.
\enum to document an enumeration type.
\fn to document a function.
\var to document a variable or typedef or enum value.
\def to document a #define.
\typedef to document a type definition."

"Unlike standard Markdown and Github Flavored Markdown doxygen will not touch internal underscores or stars or tildes, so the following will appear as-is:

a_nice_identifier
Furthermore, a * or _ only starts an emphasis and a ~ only starts a strikethrough if

it is followed by an alphanumerical character, and
it is preceded by a space, newline, or one the following characters <{([,:;
An emphasis or a strikethrough ends if

it is not followed by an alphanumerical character, and
it is not preceded by a space, newline, or one the following characters ({[<=+-\@
Lastly, the span of the emphasis or strikethrough is limited to a single paragraph."

"Note that unlike standard Markdown, doxygen leaves the following untouched.

A `cool' word in a `nice' sentence."


 There are each-blocks separating the documentation until the next paragraph or
 until the next each-block, \@title, (because input comes from `stdin`, there
 is no standard way we can know the title,) \@param{<param1>[, ...]}, \@author,
 \@std, \@depend, \@version{<version>}, \@fixme, \@return,
 \@throws{<exception1>[, ...]}, \@implements, \@order, \@allow, (the latter
 allows `static` functions to make it into the documentation and is not
 printed.)

 @title Scanner.c.re
 @author Neil
 @version 2019-06
 @std C89
 @depend re2c (\url{http://re2c.org/})
 @fixme Different doc comments need new paragraphs.
 @fixme Lists in comments, etc.
 @fixme {void A_BI_(Create, Thing)(void)} -> {<A>Create<BI>Thing(void)}.
 @fixme Trigraph support, (haha.)
 @fixme Old-style function support.
 @fixme `re2c` appends a comma at the end of the enumeration list, not
 compliant with C90.
 @fixme '\~' should \&nbsp; and something should give a slim space "\\," but
 non-breaking, (is it?) */

#include <stdio.h>  /* printf sprintf */
#include <string.h> /* memset strchr */
/* #define NDEBUG */
#include <assert.h> /* assert */
#include <limits.h> /* INT_MAX */
#include <errno.h>  /* errno EILSEQ */

/* X-Marcos are great for debugging. */
#define PARAM(A) A
#define STRINGISE(A) #A
#define PARAM2_A(A, B) A
#define PARAM2_B(A, B) B
#define STRINGISE2_A(A, B) #A
#define PARAM3_A(A, B, C) A
#define PARAM3_B(A, B, C) B
#define PARAM3_C(A, B, C) C
#define STRINGISE3_A(A, B, C) #A

/* Define `Symbols` -- these are the numerical values given to a section of
 text. The prefix of symbols themselves have meaning; see \see{append}. */
#define SYMBOL(X) \
	/* EOF -- 0. */ \
	X(END, '~', 0), \
	/* `C` syntax. */ \
	X(C_OPERATOR, '*', &lit), X(C_COMMA, ',', &lit), X(C_SEMI, ';', &lit), \
	X(C_LBRACE, '{', &lit), X(C_RBRACE, '}', &lit), X(C_LPAREN, '(', &lit), \
	X(C_RPAREN, ')', &lit), X(C_LBRACK, '[', &lit), X(C_RBRACK, ']', &lit), \
	X(C_CONSTANT, '#', &lit), X(C_ID, 'x', &lit), \
	X(C_ID_ONE_GENERIC, '1', &gen1), X(C_ID_TWO_GENERICS, '2', &gen2), \
	X(C_ID_THREE_GENERICS, '3', &gen3), X(C_STRUCT, 's', &lit), \
	X(C_UNION, 's', &lit), X(C_ENUM, 's', &lit), X(C_TYPEDEF, 't', &lit), \
	X(C_STATIC, 'z', &lit), X(C_VOID, 'v', &lit), X(C_END_BLOCK, ';', 0), \
	/* Document syntax. */ \
	X(TAG_TITLE, '@', &lit), X(TAG_PARAM, '@', &lit), \
	X(TAG_AUTHOR, '@', &lit), X(TAG_STD, '@', &lit), X(TAG_DEPEND, '@', &lit), \
	X(TAG_VERSION, '@', &lit), X(TAG_FIXME, '@', &lit), \
	X(TAG_RETURN, '@', &lit), X(TAG_THROWS, '@', &lit), \
	X(TAG_IMPLEMENTS, '@', &lit), X(TAG_ORDER, '@', &lit), \
	X(TAG_ALLOW, '@', &lit), \
	/* Meaning/escapes document syntax. */ \
	X(DOC_BEGIN, '~', 0), X(DOC_END, '~', 0), X(DOC_WORD, 'w', &lit), \
	X(DOC_ESCAPE, '\\', &esc_bs), X(DOC_URL, '\\', &url), \
	X(DOC_CITE, '\\', &cite), X(DOC_SEE_FN, '\\', &see), \
	X(DOC_SEE_DECL, '\\', &see), X(DOC_NEWLINE, 'n', &par), \
	/* `like this` or _like this_ or {like, this}. */ \
	X(MATH_BEGIN, '`', &math), X(MATH_END, '`', &math), \
	X(EM_BEGIN, '_', 0), X(EM_END, '_', 0), \
	X(DOC_LEFT, '{', 0), X(DOC_RIGHT, '}', 0), \
	/* Variable lists {like, this}. */ \
	X(DOC_ID, 'p', &lit), X(DOC_COMMA, '.', &lit), \
	/* URI for \url and \cite. */ \
	X(DOC_URI, 'u', 0)
enum Symbol { SYMBOL(PARAM3_A) };
static const char *const symbols[] = { SYMBOL(STRINGISE3_A) };
static const char symbol_mark[] = { SYMBOL(PARAM3_B) };


/** `Token` has a `Symbol` and is associated with an area of the text. */
struct Token {
	enum Symbol symbol;
	const char *from;
	int length;
	size_t line;
};
static void token_to_string(const struct Token *s, char (*const a)[12]) {
	/*int len = s->length >= 5 ? 5 : s->length;
	sprintf(*a, "%.4s<%.*s>", symbols[s->symbol], len, s->from);*/
	strncpy(*a, symbols[s->symbol], sizeof *a - 1);
	(*a)[sizeof *a - 1] = '\0';
}
#define ARRAY_NAME Token
#define ARRAY_TYPE struct Token
#define ARRAY_TO_STRING &token_to_string
#include "../src/Array.h"


/** `Tag` is a specific structure of array of `Token` representing @-tags. */
struct Tag {
	struct Token token;
	struct TokenArray header;
	struct TokenArray contents;
};
static void tag_to_string(const struct Tag *t, char (*const a)[12]) {
	strncpy(*a, symbols[t->token.symbol], sizeof *a - 1);
	(*a)[sizeof *a - 1] = '\0';
}
static void tag_init(struct Tag *const tag) {
	assert(tag);
	TokenArray(&tag->header);
	TokenArray(&tag->contents);
	/* FIXME!! Token(&tag->token);*/
}
#define ARRAY_NAME Tag
#define ARRAY_TYPE struct Tag
#define ARRAY_TO_STRING &tag_to_string
#include "../src/Array.h"
static void tag_array_remove(struct TagArray *const ta) {
	struct Tag *t;
	if(!ta) return;
	while((t = TagArrayPop(ta)))
		TokenArray_(&t->header), TokenArray_(&t->contents);
	TagArray_(ta);
}


/* Define the sections of output. */
#define SECTION(X) X(HEADER), X(DECLARATION), X(FUNCTION)
enum Section { SECTION(PARAM) };
static const char *const sections[] = { SECTION(STRINGISE) };


/** `Segment` is classified to a section of the document and can have
 documentation including tags and code. */
struct Segment {
	enum Section section;
	struct TokenArray doc, code;
	struct TagArray tags;
};
static void segment_init(struct Segment *const segment) {
	assert(segment);
	segment->section = HEADER; /* Default. */
	TokenArray(&segment->doc);
	TokenArray(&segment->code);
	TagArray(&segment->tags);
}
static void segment_to_string(const struct Segment *seg, char (*const a)[12]) {
	strncpy(*a, sections[seg->section], sizeof *a - 1);
	(*a)[sizeof *a - 1] = '\0';
}
#define ARRAY_NAME Segment
#define ARRAY_TYPE struct Segment
#define ARRAY_TO_STRING &segment_to_string
#include "../src/Array.h"


/** This is the top-level parser. */
static struct SegmentArray doc;

static void doc_(void) {
	struct Segment *seg;
	while((seg = SegmentArrayPop(&doc)))
		TokenArray_(&seg->doc), TokenArray_(&seg->code),
		tag_array_remove(&seg->tags);
	SegmentArray_(&doc);
}

/***********/

/* Define {CharArray}, a vector of characters -- dynamic string. */
#define ARRAY_NAME Char
#define ARRAY_TYPE char
#include "../src/Array.h"

/***********/

/* This defines `ScanState`; the trailing comma on an `enum` is not proper
 `C90`, hopefully they will fix it. */
/*!types:re2c*/

/** Scanner reads a file and extracts semantic information. */
struct Scanner {
	/* `buffer` {re2c} variables. These point directly into {buffer}. */
	const char *marker, *ctx_marker, *from, *cursor;
	/* Weird {c2re} stuff: these fields have to come after when >5? */
	struct CharArray buffer;
	enum ScanState state;
	enum Symbol symbol;
	int indent_level;
	int ignore_block;
	size_t line, doc_line;
} scanner;

/** Unloads Scanner from memory. */
static void Scanner_(void) {
	scanner.marker = scanner.ctx_marker = scanner.from = scanner.cursor = 0;
	CharArray_(&scanner.buffer);
	scanner.state = yyccode; /* Generated by `re2c`. */
	scanner.symbol = END;
	scanner.indent_level = 0;
	scanner.ignore_block = 0;
	scanner.line = scanner.doc_line = 0;
}

/** New Scanner. Reads from `stdin` until done; it doesn't make sense to
 call this twice since the input is consumed.
 @return Success.
 @throws{malloc, fread}
 @throws{EILSEQ} File has embedded nulls. */
static int Scanner(void) {
	const size_t granularity = 1024;
	char *read_here, *zero;
	size_t nread, zero_len;
	/* Read all contents from `stdin` at once. */
	do {
		if(!(read_here = CharArrayBuffer(&scanner.buffer, granularity))
			|| (nread = fread(read_here, 1, granularity, stdin), ferror(stdin))
			|| !CharArrayAddSize(&scanner.buffer, nread)) goto catch;
	} while(nread == granularity);
	/* Embed '\0' on the end for simple lexing. */
	if(!(zero = CharArrayNew(&scanner.buffer))) goto catch;
	*zero = '\0';
	scanner.state = yyccode;
	/* Point these toward the first char; `buffer` is necessarily done
	 growing, or we could not do this. */
	scanner.marker = scanner.ctx_marker = scanner.from = scanner.cursor
		= CharArrayGet(&scanner.buffer);
	scanner.line = scanner.doc_line = 1;
	/* We use simplified sentinel method of detecting EOF, so the file can have
	 no embedded '\0'. */
	{
		const char *const buffer = CharArrayGet(&scanner.buffer);
		zero_len = (size_t)(strchr(buffer, '\0') - buffer);
		if(zero_len != CharArraySize(&scanner.buffer) - 1)
			{ errno = EILSEQ; fprintf(stderr,
			"Expects Modified UTF-8 encoding; embedded '\\0' at byte %lu/%lu."
			"\n", (unsigned long)zero_len,
			(unsigned long)CharArraySize(&scanner.buffer) - 1); goto catch; }
	}
	return 1;
catch:
	Scanner_();
	return 0;
}

/** Prints line info in a static buffer. */
static const char *pos(void) {
	static char pos[512];
	const int max_size = 32;
	int is_truncated = (scanner.from + max_size < scanner.cursor) ? 1 : 0;
	int len = is_truncated ? max_size : (int)(scanner.cursor - scanner.from);
	assert(scanner.from <= scanner.cursor);
	sprintf(pos, "line %lu, indent %d, %s: \"%.*s\"",
		(unsigned long)scanner.line, scanner.indent_level,
		symbols[scanner.symbol], len, scanner.from);
	return pos;
}

static void token_current(struct Token *const token, const enum Symbol symbol) {
	assert(token && scanner.from && scanner.from <= scanner.cursor);
	token->symbol = symbol;
	token->from = scanner.from;
	if(scanner.from + INT_MAX < scanner.cursor) {
		fprintf(stderr, "Length of token truncated to %d;\n%s.\n", INT_MAX,
			pos());
		token->length = INT_MAX;
	} else {
		token->length = (int)(scanner.cursor - scanner.from);
	}
	token->line = scanner.line;
}

/*!re2c
re2c:yyfill:enable   = 0;
re2c:define:YYCTYPE  = char;
re2c:define:YYCURSOR = scanner.cursor;
re2c:define:YYMARKER = scanner.marker; // Rules overlap.
re2c:define:YYCTXMARKER = scanner.ctx_marker;
re2c:define:YYCONDTYPE = "ScanState";
re2c:define:YYGETCONDITION = "scanner.state";
re2c:define:YYGETCONDITION:naked = 1;
re2c:define:YYSETCONDITION = "scanner.state = @@;";
re2c:define:YYSETCONDITION:naked = 1;

// Eof is marked by null when preparing files for lexing.
eof = "\x00";
whitespace = [ \t\v\f];
newline = "\n" | "\r" "\n"?;

// Words can be composed of anything except:
// " \t\n\v\f\r" whitespace and newline;
// "*" potential end-of-comment;
// "\\" escape;
// "`" or "_" (at the beginning or end) for em;
// "@" (at the beginning) for each-tag;
// "<" (at the beginning) ">" (at the end) for links;
// "\x00" eof.
word_base = [^ \t\n\v\f\r*\\`_@<>\x00];
word_begin = word_base | ">";
word_in    = word_begin | "@" | "<";
word_end   = word_begin | "@" | "<";
word = word_base | (word_begin word_in* word_end);
// fixme: < > @ _ ` by themselves should be considered words. Not sure how to do that.

begin_doc = "/""*"+;
end_doc = "*"+"/";
art = whitespace* "*"? newline " *";
comment_break = "/" "*"+ "*" "/";
begin_comment = "/""*";
end_comment = "*""/";
cxx_comment = "//" [^\n]*;
macro = ("#" | "%:");
// @fixme No trigraph support.
// char_type = "u8"|"u"|"U"|"L"; <- These get caught in id; don't care.
oct = "0" [0-7]*;
dec = [1-9][0-9]*;
hex = '0x' [0-9a-fA-F]+;
frc = [0-9]* "." [0-9]+ | [0-9]+ ".";
exp = 'e' [+-]? [0-9]+;
flt = (frc exp? | [0-9]+ exp) [fFlL]?;
number = (oct | dec | hex | flt) [uUlL]*;
operator = ":" | "..." | "::" | "?" | "+" | "-" | "*" | "/" | "%" | "^"
	| "xor" | "&" | "bitand" | "|" | "bitor" | "~" | "compl" | "!" | "not"
	| "=" | "<" | ">" | "==" | "+=" | "-=" | "%=" | "^=" | "xor_eq"
	| "&=" | "and_eq" | "|=" | "or_eq" | "<<" | ">>" | ">>=" | "<<="
	| "!=" | "not_eq" | "<=" | ">=" | "&&" | "and" | "||" | "or" | "++"
	| "--" | "." | "->";
// Extension (hack) for generic macros; if one names them this way, it will
// be documented nicely; the down side is, these are legal names for
// identifiers; will be confused if you name anything this way that IS an
// identifier. Don't do that.
generic = [A-Z]+ "_";
// Supports only C90 ids. That would be complicated. I suppose you could hack
// it to accept a super-set?
id = [a-zA-Z_][a-zA-Z_0-9]*;
generic_id = (("<" id ">")? id)+;
// <https://tools.ietf.org/html/rfc3986#appendix-B> and also
// " \t\n\v\f\r*<>&\x00" disallowed because then it crashes / escapes comment.
uri_scheme = ([^:/?# \t\n\v\f\r*<>&\x00]+ ":");
uri_authority = ("//" [^/?# \t\n\v\f\r*<>&\x00]*);
uri_path = [^?# \t\n\v\f\r*<>&\x00]*;
uri_query = ("?" [^# \t\n\v\f\r*<>&\x00]*);
uri_fragment = ("#" [^ \t\n\v\f\r*<>&\x00]*);
absolute_uri = uri_scheme uri_authority uri_path uri_query? uri_fragment?;
relative_uri = uri_scheme? uri_authority? uri_path uri_query? uri_fragment?;
// Citation format. Not authoritative.
author = [A-Z][A-Za-z'`-]+; // Fixme: No!!! UTF-8
etalia = "et" whitespace+ "al" "."?;
authorsep = ","? whitespace* ("and" | "&" | whitespace) whitespace*;
closing = ","? whitespace*;
date = [1-3][0-9][0-9][0-9];
page = ","? whitespace* (("pp" | "p") "."?)? whitespace*
	[0-9]+ (whitespace* "-"{1,2} whitespace* [0-9]+)?;
citation = whitespace* author (authorsep author)*
	(closing etalia)? closing date page? whitespace*;
*/

/** Scans. */
static enum Symbol scan(void) {
	scanner.doc_line = scanner.line;
reset:
	scanner.from = scanner.cursor;
scan:
/*!re2c
	// Oops, don't know how to deal with that.
	<*> * { return fprintf(stderr, "Unknown;\n%s.\n", pos()),
		errno = EILSEQ, END; }
	// Everything stops at EOF.
	<*> "\x00" {
		if(scanner.state != yyccode || scanner.indent_level)
			fprintf(stderr, "Unexpected EOF;\n%s.\n", pos()), errno = EILSEQ;
		return END;
	}
	// Ignore whitespace everywhere.
	<*> whitespace+ { goto reset; }
	// Newlines are generally ignored but documentation counts for paragraphs.
	<*> newline {
		scanner.line++;
		if(scanner.state == yycdoc) return DOC_NEWLINE;
		else if(scanner.state == yycstring || scanner.state == yyccharacter)
			return fprintf(stderr, "String syntax;\n%s.\n", pos()),
			errno = EILSEQ, END;
		else if(scanner.state == yycmacro) scanner.state = yyccode;
		goto reset;
	}

	// Continuation.
	<string, character, macro> "\\" newline { scanner.line++; goto scan; }
	<string> "\"" { scanner.state = yyccode; return C_CONSTANT; }
	<character> "'" { scanner.state = yyccode; return C_CONSTANT; }
	<string, character> "\\". { goto scan; }
	<comment> end_comment :=> code
	<macro_comment> end_comment :=> macro
	// C++ comments we aren't concerned with.
	<code, macro> cxx_comment { goto reset; }
	// With flattening the `ScanState` stack, this is not actually worth
	// the effort; honestly, it's not going to matter.
	<macro> begin_doc / [^/] { return fprintf(stderr,
		"Documentation inside macro;\n%s.\n", pos()), errno = EILSEQ, END; }
	<code> comment_break { goto reset; } // Like this: /*****/.
	<code> begin_comment :=> comment
	<macro> begin_comment :=> macro_comment
	<code> macro :=> macro
	<code> "L"? "\"" :=> string
	<code> "'" :=> character
	<code> number       { return C_CONSTANT; }
	<code> operator     { return C_OPERATOR; }
	<code> generic      { return C_ID_ONE_GENERIC; }
	<code> generic generic { return C_ID_TWO_GENERICS; }
	<code> generic generic generic { return C_ID_THREE_GENERICS; }
	<code> "struct"     { return C_STRUCT; }
	<code> "union"      { return C_UNION; }
	<code> "enum"       { return C_ENUM; }
	<code> "typedef"    { return C_TYPEDEF; }
	<code> "static"     { return C_STATIC; }
	<code> "void"       { return C_VOID; }
	<code> ("{" | "<%") { scanner.indent_level++; return C_LBRACE; }
	<code> ("}" | "%>") { scanner.indent_level--; return C_RBRACE; }
	<code> ("[" | "<:") { return C_LBRACK; }
	<code> ("]" | ":>") { return C_RBRACK; }
	<code> "("          { return C_LPAREN; }
	<code> ")"          { return C_RPAREN; }
	<code> ","          { return C_COMMA; }
	<code> ";"          { return C_SEMI; }
	<code> id           { return C_ID; }

	<code> begin_doc / [^/] { return scanner.state = yycdoc, DOC_BEGIN; }
	// Also newlines in comments should be optionally ascii-art.
	<doc, math, em> art / [^/] {
		scanner.line++;
		if(scanner.state == yycdoc) return DOC_NEWLINE;
		goto reset;
	}
	<doc, math, em> "\\*""/" { return fprintf(stderr,
		"Escape past end of documentation;\n%s.\n", pos()),
		errno = EILSEQ, END; }
	<math, em> end_doc { return fprintf(stderr,
		"Not finished at end of documentation;\n%s.\n", pos()),
		errno = EILSEQ, END; }
	<doc> end_doc { return scanner.state = yyccode, DOC_END; }

	<doc, math, em> word { return DOC_WORD; }
	<doc, math, em> "\\"[^*] { return DOC_ESCAPE; }
	<doc, math, em> "\\*" / [^/] { return DOC_ESCAPE; }
	<doc> "_" { return scanner.state = yycem, EM_BEGIN; }
	<em> "_" { return scanner.state = yycdoc, EM_END; }
	<doc> "`" { return scanner.state = yycmath, MATH_BEGIN; }
	<math> "`" { return scanner.state = yycdoc, MATH_END; }

	// These are recognised in the documentation as stuff.
	// no, <fn:<fn>> or <decl:<decl>>; meh.
	// <doc> "\\see"  { return scanner.state = yycparam_begin, DOC_SEE; }
	<doc> "<" absolute_uri ">" { return DOC_URL; }
	<doc> "<" citation ">" { return DOC_CITE; }
	<doc> "<fn:" generic_id ">" { return DOC_SEE_FN; }
	<doc> "<decl:" generic_id ">" { return DOC_SEE_DECL; }

	// These are tags.
	<doc> "@title"      { return TAG_TITLE; }
	<doc> "@param"      { return scanner.state = yycparam_begin, TAG_PARAM; }
	<doc> "@author"     { return TAG_AUTHOR; }
	<doc> "@std"        { return TAG_STD; }
	<doc> "@depend"     { return TAG_DEPEND; }
	<doc> "@version"    { return TAG_VERSION; }
	<doc> "@fixme"      { return TAG_FIXME; }
	<doc> "@return"     { return TAG_RETURN; }
	<doc> "@throws"     { return scanner.state = yycparam_begin, TAG_THROWS; }
	<doc> "@implements" { return TAG_IMPLEMENTS; }
	<doc> "@order"      { return TAG_ORDER; }
	<doc> "@allow"      { return TAG_ALLOW; }

	// Parameter lists.
	<param_begin> "{" { return scanner.state = yycparam_item, DOC_LEFT; }
	<param_item>  id  { return scanner.state = yycparam_more, DOC_ID; }
	<param_more>  "," { return scanner.state = yycparam_item, DOC_COMMA; }
	<param_more>  "}" { return scanner.state = yycdoc,        DOC_RIGHT; }
	<param_begin, param_item, param_more> * {
		return fprintf(stderr, "Unrecognised in parameter list;\n%s.\n", pos()),
		errno = EILSEQ, END; }
*/
}

/* Include auto-generated `Sorter.h` from `Sorter.h.re`; this defines
 `static int sort(const enum Symbol symbol)`. */
#include "../build/Sorter.h"

int main(int argc, char **argv) {
	int is_done = 0;

	/* https://stackoverflow.com/questions/10293387/piping-into-application-run-under-xcode/13658537 */
	if (argc == 2 && strcmp(argv[1], "debug") == 0 ) {
		const char *test_file_path = "/Users/neil/Movies/Cdoc/foo.c";
		fprintf(stderr, "== [RUNNING IN DEBUG MODE with %s]==\n\n",
			test_file_path);
		freopen(test_file_path, "r", stdin);
	}

	if(!Scanner()) goto catch;
	while((scanner.symbol = scan()))
		sort(scanner.symbol), printf("Recorded %s.\n", pos());
	if(errno) goto catch;
	{
		struct Segment *segment = 0;
		fputs("\n -- Print out: --\n", stdout);
		while((segment = SegmentArrayNext(&doc, segment))) {
			struct Tag *tag = 0;
			printf("Segment(%s):\n\tdoc: %s.\n\tcode: %s.\n",
				sections[segment->section], TokenArrayToString(&segment->doc),
				TokenArrayToString(&segment->code));
			while((tag = TagArrayNext(&segment->tags, tag))) {
				printf("\t%s{%s} %s.\n", symbols[tag->token.symbol],
					TokenArrayToString(&tag->header),
					TokenArrayToString(&tag->contents));
			}
		}
		fputc('\n', stdout);
	}
	is_done = 1;
	goto finally;

catch:
	perror("scanner");

finally:
	doc_();
	Scanner_();

	return is_done ? EXIT_SUCCESS : EXIT_FAILURE;
}
