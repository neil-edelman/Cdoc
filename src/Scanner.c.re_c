/** 2019 Neil Edelman, distributed under the terms of the
 [MIT License](https://opensource.org/licenses/MIT).

 This is a context-sensitive lexer intended to process parts of a `C`
 compilation unit and extract documentation. This documentation is an even more
 stripped-down, simplified, sort-of version of `Markup` then is used in
 `Doxygen`, with the intent of making it (much) stricter and simpler, and also
 suitable for sharing and compiling. This does not do any compiling, just very
 basic text-parsing, including the macro `A_B_(Foo,Bar) -> <A>Foo<B>Bar`
 (fixme).

 Documentation commands are { "/" "*" "*"+ } and are ended with { "*"+ "/" },
 but not { "/" "*"+ "*" "/" }; one can still use this as a code break. You can
 have an asterisk at the front, like Kernel comments, or asterisks all over
 like some crazy ASCII art, (unfortunately, this causes problems with lists
 being started with "*", so start them with "-".) All documentation goes at
 most two lines above what it documents or it's appended to the header.
 Multiple documentation on the same command is appended. Everything that's not
 a function is considered a declaration for the purpose of the parser (fixme).
 Two hard returns is a paragraph.

 "\\" escapes whatever comes after, with one exception "\\," inserts a  and
 backslash-end-comment is nonsense and will not compile. When two or more
 definitions are present in a single statement, the first one is used. Embedded
 inline in the documentation,

 -* \_ _emphasised_;
 -* \` `code/math`;
 -* \<url\>;
 -* \<Source, 1999, pp. 1-2\>;
 -* \<fn:\<function\>\>;
 -* \<tag:\<struct|union|enum\>\> (fixme);
 -* \<typedef:\<typedef\>\> (fixme);
 -* \<data:\<identifier\>\> (fixme);
 -* \[The link text\](url);
 -* \!\[Caption text\](/path/to/img.jpg);
 -* lists with "\ -* "; lists can be anywhere and don't nest;
 -* a tab causes all the line after to be preformatted;
 -* \~ non-breaking space;
 -* \\, non-breaking thin space (U+202F HTML &#8239; for working with units.)

 Each-block-tags separate the documentation until the next paragraph (fixme) or
 until the
 next each-block-tag, and specify a specific documentation structure.
 Each-block-tags that overlap are concatenated in the file order. Not all of
 these are applicable for all segments of text. These are:

 -* \@title;
 -* \@param[<param1>[, ...]];
 -* \@author;
 -* \@std (remove fixme);
 -* \@depend;
 -* \@version[<version>];
 -* \@fixme (remove fixme);
 -* \@bug (fixme);
 -* \@return;
 -* \@throws[<exception1>[, ...]];
 -* \@implements;
 -* \@order;
 -* and \@allow, the latter being to allow `static` functions in the
    documentation.

 Things that are not planned for inclusion,

 -* headers;
 -* block quotes "> ";
 -* lists with "*", "+", numbered, or multi-level;
 -* horizontal rules;
 -* emphasis by *, **, \_\_;
 -* strikethrough;
 -* code spans by \`\`, _etc_;
 -* table of contents;
 -* tables;
 -* fenced code blocks;
 -* HTML blocks;
 -* '/ * !', '/ / /', '/ / !';
 -* \\brief;
 -* '/ * ! <', '/ * * <', '/ / ! <', '/ / / <': not needed; automatically
    concatenates;
 -* [in], [out];
 -* '\\param c1' or '\@param a' -- this probably is the most departure from
    normal documentation generators, but it's confusing having the text and the
    variable be indistinguishable;
 -* \!\[Caption text\](/path/to/img.jpg "Image title");
 -* \[The link text\](http://example.net/ "Link title");
 -* instead of \\struct, \\union, \\enum, \\var, \\typedef, just insert the
    documentation comment above the thing; use \<decl:<thing>\> to reference;
 -* \\def;
 -* instead of \\fn, just insert the documentation comment above the function;
    use \<fn:\<function\>\> to reference.

"Unlike standard Markdown and Github Flavored Markdown doxygen will not touch
 internal underscores or stars or tildes, so the following will appear as-is:
 a_nice_identifier
Furthermore, a * or _ only starts an emphasis if
 it is followed by an alphanumerical character, and
 it is preceded by a space, newline, or one the following characters <{([,:;
An emphasis or a strikethrough ends if
 it is not followed by an alphanumerical character, and
 it is not preceded by a space, newline, or one the
 following characters ({[<=+-\@
Lastly, the span of the emphasis or strikethrough is limited to a single
 paragraph."
"Note that unlike standard Markdown, doxygen leaves the following untouched.
A `cool' word in a `nice' sentence."

 @title Scanner.c.re
 @author Neil
 @version 2019-06
 @std C89
 @depend [re2c](http://re2c.org/)
 @fixme Different doc comments need new paragraphs.
 @fixme `void A_BI_(Create, Thing)(void)` -> `<A>Create<BI>Thing(void)`.
 @fixme Trigraph support, (haha.)
 @fixme Old-style function support.
 @bug `re2c` appends a comma at the end of the enumeration list, not
 compliant with C90. */

#include <stdio.h>  /* printf sprintf */
#include <string.h> /* memset strchr */
/* #define NDEBUG */
#include <assert.h> /* assert */
#include <limits.h> /* INT_MAX */
#include <errno.h>  /* errno EILSEQ */

#include "../src/XMacros.h"
#include "../src/Namespace.h"
#include "../src/Semantic.h"

/* Define `Symbols` -- these are the numerical values given to a section of
 text. Don't change these without changing the code in `Semantic.c.re`. */
#define SYMBOL(X) \
	/* EOF -- marked '\0' in memory. */ \
	X(END, '\0', 0), \
	/* `C` syntax; 2nd is other stuff than '@'/'~' for inclusion in marker. */ \
	X(OPERATOR, '*', &lit), X(COMMA, ',', &lit), X(SEMI, ';', &lit), \
	X(LBRACE, '{', &lit), X(RBRACE, '}', &lit), X(LPAREN, '(', &lit), \
	X(RPAREN, ')', &lit), X(LBRACK, '[', &lit), X(RBRACK, ']', &lit), \
	X(CONSTANT, '#', &lit), X(ID, 'x', &lit), \
	X(ID_ONE_GENERIC, '1', &gen1), X(ID_TWO_GENERICS, '2', &gen2), \
	X(ID_THREE_GENERICS, '3', &gen3), X(STRUCT, 's', &lit), \
	X(UNION, 's', &lit), X(ENUM, 's', &lit), X(TYPEDEF, 't', &lit), \
	X(STATIC, 'z', &lit), X(VOID, 'v', &lit), X(ELLIPSES, '.', &lit), \
	/* Each-block-tags; 2nd is '@' because we want them to have special
	 meaning. */ \
	X(TAG_TITLE, '@', &lit), X(TAG_PARAM, '@', &lit), \
	X(TAG_AUTHOR, '@', &lit), X(TAG_STD, '@', &lit), X(TAG_DEPEND, '@', &lit), \
	X(TAG_VERSION, '@', &lit), X(TAG_FIXME, '@', &lit), \
	X(TAG_RETURN, '@', &lit), X(TAG_THROWS, '@', &lit), \
	X(TAG_IMPLEMENTS, '@', &lit), X(TAG_ORDER, '@', &lit), \
	X(TAG_ALLOW, '@', &lit), \
	/* Documentation syntax; 2nd is '~' because it's documentation, it's just
	 comments as far as `C` is concerned. */ \
	X(DOC_BEGIN, '~', 0), X(DOC_END, '~', 0), \
	X(WORD, '~', &lit), X(SPACE, '~', 0), X(NEWLINE, '~', &par), \
	X(NBSP, '~', 0), X(NBTHINSP, '~', 0), X(ESCAPE, '~', &esc_bs), \
	/* Like <http://foo.com/>, <Cite1999>, [Foo](http://foo.com),
	 ![Foo](foo.png), <fn:foo>, _etc_. */ \
	X(URL, '~', &url), X(CITE, '~', &cite), X(LINK, '~', 0), \
	X(IMAGE, '~', 0), X(SEE_FN, '~', &see), X(SEE_TAG, '~', &see), \
	X(SEE_TYPEDEF, '~', &see), X(SEE_DATA, '~', &see), \
	/* Like `this` or _this_. */ \
	X(MATH_BEGIN, '~', &math), X(MATH_END, '~', &math), \
	X(EM_BEGIN, '~', 0), X(EM_END, '~', 0), \
	/* Like @param[a, b, c]. */ \
	X(DOC_LEFT, '~', 0), X(DOC_RIGHT, '~', 0), \
	X(DOC_ID, '~', &lit), X(DOC_COMMA, '~', &lit), \
	/* List items. " -* " */ \
	X(LIST_ITEM, '~', 0), \
	/* Preformated. */ \
	X(PREFORMATED, '~', 0)
enum Symbol { SYMBOL(PARAM3_A) };
static const char *const symbols[] = { SYMBOL(STRINGISE3_A) };
static const char symbol_marks[] = { SYMBOL(PARAM3_B) };


/** `Token` has a `Symbol` and is associated with an area of the text. */
struct Token {
	enum Symbol symbol;
	const char *from;
	int length;
	size_t line;
};
static void token_to_string(const struct Token *s, char (*const a)[12]) {
	/*int len = s->length >= 5 ? 5 : s->length;
	sprintf(*a, "%.4s<%.*s>", symbols[s->symbol], len, s->from);*/
	strncpy(*a, symbols[s->symbol], sizeof *a - 1);
	(*a)[sizeof *a - 1] = '\0';
}
#define ARRAY_NAME Token
#define ARRAY_TYPE struct Token
#define ARRAY_TO_STRING &token_to_string
#include "../src/Array.h"


/** `Tag` is a specific structure of array of `Token` representing @-tags. */
struct Tag {
	enum Symbol symbol;
	struct TokenArray header;
	struct TokenArray contents;
};
static void tag_to_string(const struct Tag *t, char (*const a)[12]) {
	strncpy(*a, symbols[t->symbol], sizeof *a - 1);
	(*a)[sizeof *a - 1] = '\0';
}
#define ARRAY_NAME Tag
#define ARRAY_TYPE struct Tag
#define ARRAY_TO_STRING &tag_to_string
#include "../src/Array.h"
static void tag_array_remove(struct TagArray *const ta) {
	struct Tag *t;
	if(!ta) return;
	while((t = TagArrayPop(ta)))
		TokenArray_(&t->header), TokenArray_(&t->contents);
	TagArray_(ta);
}


/** `Segment` is classified to a section of the document and can have
 documentation including tags and code. */
struct Segment {
	enum Namespace namespace;
	struct TokenArray doc, code;
	struct TagArray tags;
};
static void segment_to_string(const struct Segment *seg, char (*const a)[12]) {
	strncpy(*a, namespaces[seg->namespace], sizeof *a - 1);
	(*a)[sizeof *a - 1] = '\0';
}
#define ARRAY_NAME Segment
#define ARRAY_TYPE struct Segment
#define ARRAY_TO_STRING &segment_to_string
#include "../src/Array.h"

/** This is the top-level parser. */
static struct SegmentArray doc;


static void doc_(void) {
	struct Segment *seg;
	while((seg = SegmentArrayPop(&doc)))
		TokenArray_(&seg->doc), TokenArray_(&seg->code),
		tag_array_remove(&seg->tags);
	SegmentArray_(&doc);
}

/***********/

/* Define {CharArray}, a vector of characters -- dynamic string. */
#define ARRAY_NAME Char
#define ARRAY_TYPE char
#include "../src/Array.h"

/***********/

/* This defines `ScanState`; the trailing comma on an `enum` is not proper
 `C90`, hopefully they will fix it. */
/*!types:re2c*/

/** Scanner reads a file and extracts semantic information. */
struct Scanner {
	/* `re2c` variables; these point directly into `buffer`. */
	const char *marker, *ctx_marker, *from, *cursor;
	/* Weird `c2re` stuff: these fields have to come after when >5? */
	struct CharArray buffer, semantic_buffer;
	enum ScanState state;
	enum Symbol symbol;
	int indent_level;
	int ignore_block;
	size_t line, doc_line;
} scanner;

/** Unloads Scanner from memory. */
static void Scanner_(void) {
	scanner.marker = scanner.ctx_marker = scanner.from = scanner.cursor = 0;
	CharArray_(&scanner.buffer);
	CharArray_(&scanner.semantic_buffer);
	scanner.state = yyccode; /* Generated by `re2c`. */
	scanner.symbol = END;
	scanner.indent_level = 0;
	scanner.ignore_block = 0;
	scanner.line = scanner.doc_line = 0;
}

/** New Scanner. Reads from `stdin` until done; it doesn't make sense to
 call this twice since the input is consumed.
 @return Success.
 @throws[malloc, fread]
 @throws[EILSEQ] File has embedded nulls. */
static int Scanner(void) {
	const size_t granularity = 1024;
	char *read_here, *zero;
	size_t nread, zero_len;
	/* Read all contents from `stdin` at once. */
	do {
		if(!(read_here = CharArrayBuffer(&scanner.buffer, granularity))
			|| (nread = fread(read_here, 1, granularity, stdin), ferror(stdin))
			|| !CharArrayAddSize(&scanner.buffer, nread)) goto catch;
	} while(nread == granularity);
	/* Embed '\0' on the end for simple lexing. */
	if(!(zero = CharArrayNew(&scanner.buffer))) goto catch;
	*zero = '\0';
	scanner.state = yyccode;
	/* Point these toward the first char; `buffer` is necessarily done
	 growing, or we could not do this. */
	scanner.marker = scanner.ctx_marker = scanner.from = scanner.cursor
		= CharArrayGet(&scanner.buffer);
	scanner.line = scanner.doc_line = 1;
	/* We use simplified sentinel method of detecting EOF, so the file can have
	 no embedded '\0'. */
	{
		const char *const buffer = CharArrayGet(&scanner.buffer);
		zero_len = (size_t)(strchr(buffer, '\0') - buffer);
		if(zero_len != CharArraySize(&scanner.buffer) - 1)
			{ errno = EILSEQ; fprintf(stderr,
			"Expects Modified UTF-8 encoding; embedded '\\0' at byte %lu/%lu."
			"\n", (unsigned long)zero_len,
			(unsigned long)CharArraySize(&scanner.buffer) - 1); goto catch; }
	}
	return 1;
catch:
	Scanner_();
	Semantic(0);
	return 0;
}

/** Prints line info in a static buffer. */
static const char *pos(void) {
	static char pos[512];
	const int max_size = 32;
	int is_truncated = (scanner.from + max_size < scanner.cursor) ? 1 : 0;
	int len = is_truncated ? max_size : (int)(scanner.cursor - scanner.from);
	assert(scanner.from <= scanner.cursor);
	sprintf(pos, "line %lu, indent %d, %s: \"%.*s\"",
		(unsigned long)scanner.line, scanner.indent_level,
		symbols[scanner.symbol], len, scanner.from);
	return pos;
}

/** Creates a new token of `symbol` from `tokens`.
 @return Success. */
static int tokens_current(struct TokenArray *const tokens,
	const enum Symbol symbol) {
	struct Token *token;
	assert(tokens && scanner.from && scanner.from <= scanner.cursor);
	if(!(token = TokenArrayNew(tokens))) return 0;
	token->symbol = symbol;
	token->from = scanner.from;
	if(scanner.from + INT_MAX < scanner.cursor) {
		fprintf(stderr, "Length of token truncated to %d;\n%s.\n", INT_MAX,
			pos());
		token->length = INT_MAX;
	} else {
		token->length = (int)(scanner.cursor - scanner.from);
	}
	token->line = scanner.line;
	return 1;
}

static struct Tag *segment_new_tag(struct Segment *const segment,
	const enum Symbol symbol) {
	struct Tag *tag;
	assert(segment);
	if(!(tag = TagArrayNew(&segment->tags))) return 0;
	tag->symbol = symbol;
	TokenArray(&tag->header);
	TokenArray(&tag->contents);
	return tag;
}

static struct Segment *doc_new_segment(void) {
	struct Segment *segment;
	if(!(segment = SegmentArrayNew(&doc))) return 0;
	segment->namespace = NAME_PREAMBLE; /* Default. */
	TokenArray(&segment->doc);
	TokenArray(&segment->code);
	TagArray(&segment->tags);
	return segment;
}

/*!re2c
re2c:yyfill:enable   = 0;
re2c:define:YYCTYPE  = char;
re2c:define:YYCURSOR = scanner.cursor;
re2c:define:YYMARKER = scanner.marker; // Rules overlap.
re2c:define:YYCTXMARKER = scanner.ctx_marker;
re2c:define:YYCONDTYPE = "ScanState";
re2c:define:YYGETCONDITION = "scanner.state";
re2c:define:YYGETCONDITION:naked = 1;
re2c:define:YYSETCONDITION = "scanner.state = @@;";
re2c:define:YYSETCONDITION:naked = 1;

// Eof is marked by null when preparing files for lexing.
eof = "\x00";
whitespace = [ \t\v\f];
newline = "\n" | "\r" "\n"?;

// Words can be composed of anything except:
// " \t\n\v\f\r" whitespace and newline;
// "~" non-breaking space;
// "*" potential end-of-comment;
// "\\" escape;
// "`" or "_" (at the beginning or end) for em;
// "@" (at the beginning) for each-block-tag;
// "<>[]" for embedded things;
// "\x00" eof.
word_base = [^ \t\n\v\f\r~*\\`_@<>\[\]\x00];
word_begin = word_base | ">" | "]";
word_in    = word_begin | "@" | "<" | ">" | "[" | "]";
word_end   = word_begin | "@" | "<" | "[";
word = word_base | (word_begin word_in* word_end)
	| "*" | "@" | "<" | ">" | "[" | "]";
begin_doc = "/""*"+;
end_doc = "*"+"/";
art = whitespace* "*"? newline " *";
comment_break = "/" "*"+ "*" "/";
begin_comment = "/""*";
end_comment = "*""/";
cxx_comment = "//" [^\n\x00]*;
macro = ("#" | "%:");
// fixme: No trigraph support.
// char_type = "u8"|"u"|"U"|"L"; <- These get caught in id; don't care.
oct = "0" [0-7]*;
dec = [1-9][0-9]*;
hex = '0x' [0-9a-fA-F]+;
frc = [0-9]* "." [0-9]+ | [0-9]+ ".";
exp = 'e' [+-]? [0-9]+;
flt = (frc exp? | [0-9]+ exp) [fFlL]?;
number = (oct | dec | hex | flt) [uUlL]*;
operator = ":" | "..." | "::" | "?" | "+" | "-" | "*" | "/" | "%" | "^"
	| "xor" | "&" | "bitand" | "|" | "bitor" | "~" | "compl" | "!" | "not"
	| "=" | "<" | ">" | "==" | "+=" | "-=" | "%=" | "^=" | "xor_eq"
	| "&=" | "and_eq" | "|=" | "or_eq" | "<<" | ">>" | ">>=" | "<<="
	| "!=" | "not_eq" | "<=" | ">=" | "&&" | "and" | "||" | "or" | "++"
	| "--" | "." | "->";
// Extension (hack) for generic macros; if one names them this way, it will
// be documented nicely; the down side is, these are legal names for
// identifiers; will be confused if you name anything this way that IS an
// identifier. Don't do that.
generic = [A-Z]+ "_";
// Supports only C90 ids. That would be complicated. I suppose you could hack
// it to accept a super-set?
id = [a-zA-Z_][a-zA-Z_0-9]*;
generic_id = (("<" [A-Z]+ ">")? id)+;
// <https://tools.ietf.org/html/rfc3986#appendix-B> and also
// " \t\n\v\f\r*<>&\x00" disallowed because then it crashes / escapes comment.
uri_scheme = ([^:/?# \t\n\v\f\r*<>&\x00]+ ":");
uri_authority = ("//" [^/?# \t\n\v\f\r*<>&\x00]*);
uri_path = [^?# \t\n\v\f\r*<>&\x00]*;
uri_query = ("?" [^# \t\n\v\f\r*<>&\x00]*);
uri_fragment = ("#" [^ \t\n\v\f\r*<>&\x00]*);
absolute_uri = uri_scheme uri_authority uri_path uri_query? uri_fragment?;
relative_uri = uri_scheme? uri_authority? uri_path uri_query? uri_fragment?;
// Citation format. Not authoritative.
author = [A-Z][A-Za-z'`-]+; // Fixme: No!!! UTF-8
etalia = "et" whitespace+ "al" "."?;
authorsep = ","? whitespace* ("and" | "&" | whitespace) whitespace*;
closing = ","? whitespace*;
date = [1-3][0-9][0-9][0-9];
page = ","? whitespace* (("pp" | "p") "."?)? whitespace*
	[0-9]+ (whitespace* "-"{1,2} whitespace* [0-9]+)?;
citation = whitespace* author (authorsep author)*
	(closing etalia)? closing date page? whitespace*;
// Lists.
list = " -* ";
// Math/code blocks. Added after; very meh.
preformated = "\t" [^*\n\x00]*;
*/

/** Scans. */
static enum Symbol scan(void) {
	scanner.doc_line = scanner.line;
reset:
	scanner.from = scanner.cursor;
scan:
/*!re2c
	// Oops, don't know how to deal with that.
	<*> * { return fprintf(stderr, "Unknown;\n%s.\n", pos()),
		errno = EILSEQ, END; }
	// Everything stops at EOF.
	<*> "\x00" {
		if(scanner.state != yyccode || scanner.indent_level)
			fprintf(stderr, "Unexpected EOF;\n%s.\n", pos()), errno = EILSEQ;
		return END;
	}
	// Ignore whitespace everywhere.
	<*> whitespace+ { if(scanner.state == yycdoc) return SPACE; goto reset; }
	// Newlines are generally ignored but documentation counts for paragraphs.
	<*> newline {
		scanner.line++;
		if(scanner.state == yycdoc) return NEWLINE;
		else if(scanner.state == yycstring || scanner.state == yyccharacter)
			return fprintf(stderr, "String syntax;\n%s.\n", pos()),
			errno = EILSEQ, END;
		else if(scanner.state == yycmacro) scanner.state = yyccode;
		goto reset;
	}

	// Continuation.
	<string, character, macro> "\\" newline { scanner.line++; goto scan; }
	<string> "\"" { scanner.state = yyccode; return CONSTANT; }
	<character> "'" { scanner.state = yyccode; return CONSTANT; }
	<string, character> "\\". { goto scan; }
	<comment> end_comment :=> code
	<macro_comment> end_comment :=> macro
	// C++ comments we aren't concerned with.
	<code, macro> cxx_comment { goto reset; }
	// With flattening the `ScanState` stack, this is not actually worth
	// the effort; honestly, it's not going to matter.
	<macro> begin_doc / [^/] { return fprintf(stderr,
		"Documentation inside macro;\n%s.\n", pos()), errno = EILSEQ, END; }
	<code> comment_break { goto reset; } // Like this: /*****/.
	<code> begin_comment :=> comment
	<macro> begin_comment :=> macro_comment
	<code> macro :=> macro
	<code> "L"? "\"" :=> string
	<code> "'" :=> character
	<code> number       { return CONSTANT; }
	<code> operator     { return OPERATOR; }
	<code> generic      { return ID_ONE_GENERIC; }
	<code> generic generic { return ID_TWO_GENERICS; }
	<code> generic generic generic { return ID_THREE_GENERICS; }
	<code> "struct"     { return STRUCT; }
	<code> "union"      { return UNION; }
	<code> "enum"       { return ENUM; }
	<code> "typedef"    { return TYPEDEF; }
	<code> "static"     { return STATIC; }
	<code> "void"       { return VOID; }
	<code> ("{" | "<%") { scanner.indent_level++; return LBRACE; }
	<code> ("}" | "%>") { scanner.indent_level--; return RBRACE; }
	<code> ("[" | "<:") { return LBRACK; }
	<code> ("]" | ":>") { return RBRACK; }
	<code> "("          { return LPAREN; }
	<code> ")"          { return RPAREN; }
	<code> ","          { return COMMA; }
	<code> ";"          { return SEMI; }
	<code> "..."        { return ELLIPSES; }
	<code> id           { return ID; }

	<code> begin_doc / [^/] { return scanner.state = yycdoc, DOC_BEGIN; }
	// Also newlines in comments should be optionally ascii-art.
	<doc, math, em, param_item, param_more> art / [^/] {
		scanner.line++;
		if(scanner.state == yycdoc) return NEWLINE;
		goto reset;
	}
	<doc, math, em, param_item, param_more> "\\*""/" { return
		fprintf(stderr, "Escape past end of documentation;\n%s.\n", pos()),
		errno = EILSEQ, END; }
	<math, em, param_item, param_more> end_doc { return
		fprintf(stderr, "Unexpected end of documentation;\n%s.\n", pos()),
		errno = EILSEQ, END; }
	<doc> end_doc { return scanner.state = yyccode, DOC_END; }

	<doc, math, em> word { return WORD; }
	<doc, math, em> "\\"[^*,\x00] { return ESCAPE; }
	<doc, math, em> "\\," { return NBTHINSP; }
	<doc, math, em> "\\*" / [^/] { return ESCAPE; }
	<doc, math, em> "\\\x00" { return fprintf(stderr,
		"Escape past EOF;\n%s.\n", pos()), errno = EILSEQ, END; }
	<doc> "_" { return scanner.state = yycem, EM_BEGIN; }
	<em> "_" { return scanner.state = yycdoc, EM_END; }
	<doc> "`" { return scanner.state = yycmath, MATH_BEGIN; }
	<math> "`" { return scanner.state = yycdoc, MATH_END; }

	// These are recognised in the documentation as stuff. fixme: s-tags.
	<doc> "<" absolute_uri ">" { return URL; }
	<doc> "<" citation ">" { return CITE; }
	<doc> "<fn:" generic_id ">" { return SEE_FN; }
	<doc> "<tag:" generic_id ">" { return SEE_TAG; }
	<doc> "<typedef:" generic_id ">" { return SEE_TYPEDEF; }
	<doc> "<data:" generic_id ">" { return SEE_DATA; }
	<doc> "[" whitespace* (word whitespace*)+ "](" absolute_uri ")"
		{ return LINK; }
	<doc> "![" whitespace* (word whitespace*)+ "](" relative_uri ")"
		{ return IMAGE; }
	<doc> "~" { return NBSP; }
	<doc> list { return LIST_ITEM; }
	<doc> preformated { return PREFORMATED; }

	// These are tags.
	<doc> "@title"      { return TAG_TITLE; }
	<doc> "@param"      { return scanner.state = yycparam_begin, TAG_PARAM; }
	<doc> "@author"     { return TAG_AUTHOR; }
	<doc> "@std"        { return TAG_STD; }
	<doc> "@depend"     { return TAG_DEPEND; }
	<doc> "@version"    { return TAG_VERSION; }
	<doc> "@fixme"      { return TAG_FIXME; }
	<doc> "@return"     { return TAG_RETURN; }
	<doc> "@throws"     { return scanner.state = yycparam_begin, TAG_THROWS; }
	<doc> "@implements" { return TAG_IMPLEMENTS; }
	<doc> "@order"      { return TAG_ORDER; }
	<doc> "@allow"      { return TAG_ALLOW; }

	// Parameter lists.
	<param_begin> "[" { return scanner.state = yycparam_item, DOC_LEFT; }
	<param_item>  id  { return scanner.state = yycparam_more, DOC_ID; }
	<param_more>  "," { return scanner.state = yycparam_item, DOC_COMMA; }
	<param_more>  "]" { return scanner.state = yycdoc,        DOC_RIGHT; }
	<param_begin, param_item, param_more> * {
		return fprintf(stderr, "Unrecognised in parameter list;\n%s.\n", pos()),
		errno = EILSEQ, END; }
*/
}

/** Extracts the approximate meaning of `code`. Does this by copying characters
 clobbers to `semantic_buffer` in global `scanner` and then calls external
 `Semantic`. */
static enum Namespace namespace(const struct TokenArray *const code) {
	struct Token *token = 0;
	size_t size;
	char *a;
	assert(code);
	/* Copy the meanings of all the symbols into `sematic_buffer`, overriding
	 what was there. */
	CharArrayClear(&scanner.semantic_buffer);
	size = TokenArraySize(code) + 1;
	if(!(a = CharArrayBuffer(&scanner.semantic_buffer, size)))
		return perror("namespace"), NAME_PREAMBLE; /* Lazy. */
	CharArrayAddSize(&scanner.semantic_buffer, size);
	while((token = TokenArrayNext(code, token)))
		*a++ = symbol_marks[token->symbol];
	*a++ = '\0';
	assert((size_t)(a - CharArrayGet(&scanner.semantic_buffer))
		== CharArraySize(&scanner.semantic_buffer));
	/* Now it's just a string; call `Semantic`. */
	return Semantic(CharArrayGet(&scanner.semantic_buffer));
}

/** This appends the current token based on the state it was last in.
 @return Success. */
static int place(const enum Symbol symbol) {
	const char symbol_mark = symbol_marks[symbol];
	int is_differed_cut = 0;
	static struct {
		struct Segment *segment;
		struct Tag *tag;
		unsigned space, newline;
		int is_tag_header, is_ignored_code;
	} sorter = { 0, 0, 0, 0, 0, 0 }; /* This holds the sorting state. */

	/* These symbols require special consideration. */
	switch(symbol) {
	case DOC_BEGIN: /* Multiple doc comments. */
		sorter.tag = 0;
		if(!sorter.segment) return 1;
		if(!TokenArraySize(&sorter.segment->code)) sorter.segment = 0;
		printf("----CUT in preamble----\n");
		return 1;
	case DOC_END: return 1; /* Doesn't actually do something. */
	case DOC_LEFT: /* Should only happen in @foo[]. */
		if(!sorter.segment || !sorter.tag || sorter.is_tag_header)
			return fprintf(stderr, "Out-of-place '[';\n%s.\n", pos()), 0;
		sorter.is_tag_header = 1;
		return 1;
	case DOC_RIGHT:
		if(!sorter.segment || !sorter.tag || !sorter.is_tag_header)
			return fprintf(stderr, "Out-of-place ']';\n%s.\n", pos()), 0;
		sorter.is_tag_header = 0;
		return 1;
	case DOC_COMMA:
		if(!sorter.segment || !sorter.tag || !sorter.is_tag_header)
			return fprintf(stderr, "Out-of-place ',';\n%s.\n", pos()), 0;
		return 1; /* Doesn't actually do something. */
	case SPACE:   sorter.space++; return 1;
	case NEWLINE: sorter.newline++; return 1;
	case SEMI:
		if(scanner.indent_level != 0) break;
		sorter.segment->namespace = namespace(&sorter.segment->code);
		sorter.is_ignored_code = 1;
		is_differed_cut = 1;
		break;
	case LBRACE:
		if(scanner.indent_level != 1) break;
		sorter.segment->namespace = namespace(&sorter.segment->code);
		if(sorter.segment->namespace == NAME_FUNCTION)
			sorter.is_ignored_code = 1;
		break;
	case RBRACE: /* Functions don't have ';' to end them. */
		if(scanner.indent_level != 0) break;
		if(sorter.segment->namespace == NAME_FUNCTION) is_differed_cut = 1;
		break;
	default: break;
	}

	/* Make a new segment if needed. */
	if(!sorter.segment) {
		if(!(sorter.segment = doc_new_segment())) return 0;
		sorter.tag = 0;
		sorter.space = sorter.newline = 0;
		sorter.is_ignored_code = 0;
		assert(!sorter.is_tag_header);
	}

	/* Make a `token` where the context places us. */
	switch(symbol_mark) {
	case '~':
		{ /* This lazily places whitespace when other stuff is added. */
			struct TokenArray *selected = sorter.tag
				? (sorter.is_tag_header ? &sorter.tag->header
				: &sorter.tag->contents) : &sorter.segment->doc;
			const int is_para = sorter.newline > 1,
				is_space = sorter.space || sorter.newline,
				is_doc_empty = !TokenArraySize(&sorter.segment->doc),
				is_selected_empty = !TokenArraySize(selected);
			sorter.space = sorter.newline = 0;
			if(is_para) {
				/* Switch out of tag. */
				sorter.tag = 0, sorter.is_tag_header = 0;
				selected = &sorter.segment->doc;
				if(!is_doc_empty
					&& !tokens_current(&sorter.segment->doc, NEWLINE)) return 0;
			} else if(is_space) {
				if(!is_selected_empty
					&& !tokens_current(selected, SPACE)) return 0;
			}
			if(!tokens_current(selected, symbol)) return 0;
		}
		break;
	case '@':
		if(!(sorter.tag = segment_new_tag(sorter.segment, symbol))) return 0;
		assert(!sorter.is_tag_header);
		break;
	default:
		if(sorter.is_ignored_code) goto differed;
		if(!tokens_current(&sorter.segment->code, symbol)) return 0;
		break;
	}

differed:
	/* End the segment? */
	if(is_differed_cut) printf("----Differered CUT----\n"), sorter.segment = 0;

	return 1;
}

#include "../src/Out.h"

/** Entry-point.
 @param[argc, argv] If "debug", `freopens` a path that is on my computer. */
int main(int argc, char **argv) {
	int exit_code = EXIT_FAILURE;

	/* https://stackoverflow.com/questions/10293387/piping-into-application-run-under-xcode/13658537 */
	if (argc == 2 && strcmp(argv[1], "debug") == 0 ) {
		const char *test_file_path = "/Users/neil/Movies/Cdoc/foo.c";
		fprintf(stderr, "== [RUNNING IN DEBUG MODE with %s]==\n\n",
			test_file_path);
		freopen(test_file_path, "r", stdin);
	}

	if(!Scanner()) goto catch;
	while((scanner.symbol = scan()))
		place(scanner.symbol), printf("Read %s.\n", pos());
	if(errno) goto catch;
	{
		struct Segment *segment = 0;
		fputs("\n -- Print out: --\n", stdout);
		while((segment = SegmentArrayNext(&doc, segment))) {
			struct Tag *tag = 0;
			printf("Segment(%s):\n\tdoc: %s.\n\tcode: %s.\n",
				namespaces[segment->namespace],
				TokenArrayToString(&segment->doc),
				TokenArrayToString(&segment->code));
			while((tag = TagArrayNext(&segment->tags, tag))) {
				printf("\t%s{%s} %s.\n", symbols[tag->symbol],
					TokenArrayToString(&tag->header),
					TokenArrayToString(&tag->contents));
			}
			fputc('\n', stdout);
		}
	}

	{
		fputs("\n\n", stdout);
		out(&doc);
	}

	exit_code = EXIT_SUCCESS; goto finally;

catch:
	perror("scanner");

finally:
	doc_();
	Scanner_();

	return exit_code;
}
